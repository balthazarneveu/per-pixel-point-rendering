\section{Introduction}
\label{sec:intro}
The purpose of this report is a review of the paper ADOP: Approximate Differentiable One-Pixel Point Rendering \citet{ruckert2022adop}. 
Since the NERF paper published at ECCV 2020, there's been an incredible number of papers on neural rendering . Different approaches have been proposed with an underlying data structure which allows rendering novel views of a scene, such as neural radiance fields, voxels and even point-based rendering.
Let's put things simply: Point based rendering leads to images filled with holes and at first sight does not really look like an appropriate data structure to render continuous volumes.
We'll see how this data structure still leads allow to sample dense novel views of a scene.
A complete re-implementation in Pytorch of some of the key elements of the paper has been made in order to fully understand the details. 
Our code is available on~\href{https://github.com/balthazarneveu/per-pixel-point-rendering}{GitHub}.
